{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64>python -m pip install google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc \n",
    "from datetime import datetime, date, timedelta\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=Localhost;'\n",
    "                      'Database=CollectionStrategy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file('/data/docker/ProsperAirflow1_10_x/dags/keys/datalake-poc-205120.json')\n",
    "project_id = 'datalake-poc-205120'\n",
    "client = bigquery.Client(credentials=credentials,project=project_id)\n",
    "# Prepares a reference to the dataset\n",
    "dataset_ref = client.dataset('DW')\n",
    "table_ref = dataset_ref.table('treatment1')\n",
    "table = client.get_table(table_ref)  # API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-14\n",
      "2019-07-14\n"
     ]
    }
   ],
   "source": [
    "rowbatch = 2000\n",
    "\n",
    "#load variables from destination\n",
    "startdate = date.today()-timedelta(days=1) # 2019-07-11 done (next date has no rows)\n",
    "enddate = date.today()-timedelta(days=1)\n",
    "\n",
    "print(startdate)\n",
    "print(enddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-14\n"
     ]
    }
   ],
   "source": [
    "cursor = src_conn.cursor()\n",
    "\n",
    "while enddate <= startdate:\n",
    "\n",
    "    rowcount = 0\n",
    "    rowinsert = []\n",
    "    \n",
    "    cursor.execute(\"SELECT LOAN_ID, PROCESS_DATE FROM dbo.TREATMENT \\\n",
    "                    WHERE PROCESS_DATE = '{}'\".format(str(startdate)))\n",
    "    #check for rows\n",
    "    if cursor.rowcount == 0:\n",
    "        rowcount = -1 # used to escape final batch insert and move to next date\n",
    "    \n",
    "    for row in cursor:\n",
    "        rowinsert += [(row[0],row[1])]\n",
    "        rowcount += 1\n",
    "        \n",
    "        #insert batch of rows\n",
    "        if rowcount == rowbatch:\n",
    "            errors = client.insert_rows(table, rowinsert)  # API request\n",
    "            assert errors == []\n",
    "            rowcount = 0\n",
    "            rowinsert = []\n",
    "    \n",
    "    #insert remaining rows when smaller than batch\n",
    "    if rowcount != rowbatch and rowcount != -1:\n",
    "        errors = client.insert_rows(table, rowinsert)  # API request\n",
    "        assert errors == []\n",
    "    \n",
    "    print(startdate)\n",
    "    startdate = startdate-timedelta(days=1)\n",
    "         \n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
